{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Sub-Tree Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Get necessary data from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection_str = 'mysql+pymysql://root:db@localhost/GDE'\n",
    "db_connection = create_engine(db_connection_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_subtree_subjects = ['EM306', 'EM404', 'ES601', 'EM607', 'ES710', 'ES626', 'ES827', 'ES728', 'ES828']\n",
    "control_subtree_regex = [subject_codename + '.*' for subject_codename in control_subtree_subjects]\n",
    "\n",
    "control_subtree_df = pd.read_sql(\"SELECT * FROM Subject WHERE SubjectName REGEXP '\"+\"|\".join(control_subtree_regex) + \"'\", db_connection)\n",
    "control_subtree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_subject_ids = ','.join(str(subject_db_id) for subject_db_id in control_subtree_df['ID'].to_list())\n",
    "subjects_scores = pd.read_sql(\"SELECT ProfessorID, SubjectID, Coerente, ExplicaBem, Facilidade FROM ProfessorRankings WHERE SubjectID IN ({ids})\".format(ids = target_subject_ids), db_connection)\n",
    "subjects_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Determining Criteria Weights - Fuzzy SWARA\n",
    "\n",
    "![](../docs/imgs/Fuzzy-SWARA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_makers_aggregated_opinions = {'Quality Of Explanation Score' : np.array([0,0,0]), 'Coherence Score' : np.array([2/9, 1/4, 2/7]), 'Easiness Score' : np.array([2/7, 1/3, 2/5])}\n",
    "decision_makers_aggregated_optinions_df = pd.DataFrame(decision_makers_aggregated_opinions).transpose()\n",
    "decision_makers_aggregated_optinions_df = decision_makers_aggregated_optinions_df.rename_axis('Criteria').rename(columns={0:'l',1: 'm',2: 'u'})\n",
    "\n",
    "# Calculate the k matrix\n",
    "decision_makers_aggregated_optinions_df = decision_makers_aggregated_optinions_df+1\n",
    "decision_makers_aggregated_optinions_df\n",
    "\n",
    "# Calculate q Matrix\n",
    "l = decision_makers_aggregated_optinions_df.columns.get_loc('l')\n",
    "m = decision_makers_aggregated_optinions_df.columns.get_loc('m')\n",
    "u = decision_makers_aggregated_optinions_df.columns.get_loc('u')\n",
    "\n",
    "for criteria_index in range(decision_makers_aggregated_optinions_df.shape[0]):\n",
    "    decision_makers_aggregated_optinions_df.iloc[criteria_index, l] = 1 if criteria_index == 0 else decision_makers_aggregated_optinions_df.iloc[criteria_index - 1, l] / decision_makers_aggregated_optinions_df.iloc[criteria_index, u] \n",
    "    decision_makers_aggregated_optinions_df.iloc[criteria_index, m] = 1 if criteria_index == 0 else decision_makers_aggregated_optinions_df.iloc[criteria_index - 1, m] / decision_makers_aggregated_optinions_df.iloc[criteria_index, m] \n",
    "    decision_makers_aggregated_optinions_df.iloc[criteria_index, u] = 1 if criteria_index == 0 else decision_makers_aggregated_optinions_df.iloc[criteria_index - 1, u] / decision_makers_aggregated_optinions_df.iloc[criteria_index, l] \n",
    "\n",
    "# Calculate weights by normalizing the q matrix\n",
    "decision_makers_aggregated_optinions_df['l'] = decision_makers_aggregated_optinions_df['l'] / decision_makers_aggregated_optinions_df['l'].sum()\n",
    "decision_makers_aggregated_optinions_df['m'] = decision_makers_aggregated_optinions_df['m'] / decision_makers_aggregated_optinions_df['m'].sum()\n",
    "decision_makers_aggregated_optinions_df['u'] = decision_makers_aggregated_optinions_df['u'] / decision_makers_aggregated_optinions_df['u'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_makers_aggregated_optinions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Professor Ranking - Fuzzy Topsis\n",
    "\n",
    "The first analysis we will do is, through the use of fuzzy numbers to represent the 5-star scores, aggregate all the scores for the subjects the professor teaches (in our case subjects that are part of the control systems subtree). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Cleaning Data\n",
    "\n",
    "Some professors history in a specific subject may not have the minimum number of entries for scores, so they appear as NaN on the scores dataframe and need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_scores = subjects_scores.dropna()\n",
    "subjects_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Expanding 5-Star Review to Triangular Fuzzy Numbers\n",
    "\n",
    "![](../docs/imgs/Linguistic-five-Likert-scale-using-triangular-fuzzy-number.png)\n",
    "\n",
    "[Reference](https://www.researchgate.net/figure/Linguistic-five-Likert-scale-using-triangular-fuzzy-number_tbl1_365957303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisp_to_fuzzy = {1.0 : np.array([1, 1, 2]), 2.0: np.array([1, 2, 3]), 3.0: np.array([2, 3, 4]), 4.0:  np.array([3, 4, 5]), 5.0: np.array([4, 5, 5])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_subjects_scores = subjects_scores.copy()\n",
    "\n",
    "for col in ['Coerente', 'ExplicaBem', 'Facilidade']:\n",
    "    fuzzy_subjects_scores[col] = subjects_scores[col].apply(lambda val: crisp_to_fuzzy[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_subjects_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Aggregate All the scores for a professor - Aggregated Judgement Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "professors_scores_fuzzy_aggregation = []\n",
    "\n",
    "for professor_id in fuzzy_subjects_scores['ProfessorID'].unique():\n",
    "    subject_fuzzy_scores = fuzzy_subjects_scores.loc[fuzzy_subjects_scores['ProfessorID'] == professor_id]\n",
    "\n",
    "    n_scores = len(subject_fuzzy_scores)\n",
    "    easy_values = ((1/n_scores) * np.sum(np.array(subject_fuzzy_scores['Facilidade']), axis=0))\n",
    "    coherent_values = ((1/n_scores) * np.sum(np.array(subject_fuzzy_scores['Coerente']), axis=0))\n",
    "    explanation_values = ((1/n_scores) * np.sum(np.array(subject_fuzzy_scores['ExplicaBem']), axis=0))\n",
    "\n",
    "    professors_scores_fuzzy_aggregation.append({'Professor ID': professor_id, 'Easiness Score': easy_values, 'Coherence Score': coherent_values, 'Quality Of Explanation Score': explanation_values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "professors_scores_fuzzy_aggregation_df = pd.DataFrame(professors_scores_fuzzy_aggregation)\n",
    "professors_scores_fuzzy_aggregation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Normalize Aggregated Judgement Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_professors_scores_fuzzy_aggregation_df = professors_scores_fuzzy_aggregation_df.copy()\n",
    "for criteria in ['Coherence Score', 'Easiness Score', 'Quality Of Explanation Score']:\n",
    "    scores_matrix = np.stack(professors_scores_fuzzy_aggregation_df[criteria])\n",
    "    u_max = np.max(scores_matrix, axis=0)[2]\n",
    "    normalized_professors_scores_fuzzy_aggregation_df[criteria] = professors_scores_fuzzy_aggregation_df[criteria] / u_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_professors_scores_fuzzy_aggregation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Weighted and Normalized Aggregated Judgement Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_professors_scores = normalized_professors_scores_fuzzy_aggregation_df.copy()\n",
    "\n",
    "for criteria in ['Coherence Score', 'Easiness Score', 'Quality Of Explanation Score']:\n",
    "    fuzzy_weight = np.stack(decision_makers_aggregated_optinions_df.loc[criteria])\n",
    "    criteria_matrix = np.stack(professors_scores_fuzzy_aggregation_df[criteria])\n",
    "    weighted_criteria_matrix = np.multiply(criteria_matrix, fuzzy_weight)\n",
    "\n",
    "    for row_index, value in enumerate(weighted_criteria_matrix):\n",
    "        weighted_professors_scores.at[row_index, criteria] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_professors_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Define Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.1 Class Definiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_description = {'Easiness Score': [crisp_to_fuzzy[5.0], crisp_to_fuzzy[3.0], crisp_to_fuzzy[1.0]], 'Coherence Score':[crisp_to_fuzzy[5.0], crisp_to_fuzzy[3.0], crisp_to_fuzzy[1.0]], 'Quality Of Explanation Score':[crisp_to_fuzzy[5.0], crisp_to_fuzzy[3.0], crisp_to_fuzzy[1.0]]}\n",
    "classes_df = pd.DataFrame(classes_description)\n",
    "classes_df = classes_df.set_axis(['Otimo Aproveitamento', 'Aproveitamento Mediano', 'Baixo Aproveitamento'])\n",
    "classes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.2 Class Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for criteria in ['Coherence Score', 'Easiness Score', 'Quality Of Explanation Score']:\n",
    "    scores_matrix = np.stack(professors_scores_fuzzy_aggregation_df[criteria])\n",
    "    u_max = np.max(scores_matrix, axis=0)[2]\n",
    "    classes_df[criteria] = classes_df[criteria] / u_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.3 Weighted And Normalized Class Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_classes_df = classes_df.copy()\n",
    "for criteria in ['Coherence Score', 'Easiness Score', 'Quality Of Explanation Score']:\n",
    "    fuzzy_weight = np.stack(decision_makers_aggregated_optinions_df.loc[criteria])\n",
    "    class_matrix = np.stack(classes_df[criteria])\n",
    "    weighted_criteria_matrix = np.multiply(class_matrix, fuzzy_weight)\n",
    "\n",
    "    for row_index, value in enumerate(weighted_criteria_matrix):\n",
    "        weighted_classes_df.at[weighted_classes_df.index[row_index], criteria] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Easiness Score</th>\n",
       "      <th>Coherence Score</th>\n",
       "      <th>Quality Of Explanation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Otimo Aproveitamento</th>\n",
       "      <td>[0.19047619047619052, 0.25, 0.5031055900621116]</td>\n",
       "      <td>[0.2666666666666667, 0.3333333333333333, 0.279...</td>\n",
       "      <td>[0.34285714285714286, 0.41666666666666663, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aproveitamento Mediano</th>\n",
       "      <td>[0.09523809523809526, 0.15, 0.40248447204968935]</td>\n",
       "      <td>[0.13333333333333336, 0.19999999999999998, 0.2...</td>\n",
       "      <td>[0.17142857142857143, 0.24999999999999997, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baixo Aproveitamento</th>\n",
       "      <td>[0.04761904761904763, 0.05, 0.20124223602484467]</td>\n",
       "      <td>[0.06666666666666668, 0.06666666666666667, 0.1...</td>\n",
       "      <td>[0.08571428571428572, 0.08333333333333333, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Easiness Score  \\\n",
       "Otimo Aproveitamento     [0.19047619047619052, 0.25, 0.5031055900621116]   \n",
       "Aproveitamento Mediano  [0.09523809523809526, 0.15, 0.40248447204968935]   \n",
       "Baixo Aproveitamento    [0.04761904761904763, 0.05, 0.20124223602484467]   \n",
       "\n",
       "                                                          Coherence Score  \\\n",
       "Otimo Aproveitamento    [0.2666666666666667, 0.3333333333333333, 0.279...   \n",
       "Aproveitamento Mediano  [0.13333333333333336, 0.19999999999999998, 0.2...   \n",
       "Baixo Aproveitamento    [0.06666666666666668, 0.06666666666666667, 0.1...   \n",
       "\n",
       "                                             Quality Of Explanation Score  \n",
       "Otimo Aproveitamento    [0.34285714285714286, 0.41666666666666663, 0.2...  \n",
       "Aproveitamento Mediano  [0.17142857142857143, 0.24999999999999997, 0.1...  \n",
       "Baixo Aproveitamento    [0.08571428571428572, 0.08333333333333333, 0.0...  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_classes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.4 Define Ideal Solutions\n",
    "\n",
    "**Ideal Solutions For \"otimo Aproveitamento\" Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "great_class_ideal_solutions_df = pd.DataFrame(columns=weighted_classes_df.columns)\n",
    "great_class_ideal_solutions_df.loc[0] = weighted_classes_df.loc['Otimo Aproveitamento']\n",
    "great_class_ideal_solutions_df.loc[1] = weighted_classes_df.loc['Baixo Aproveitamento']\n",
    "great_class_ideal_solutions_df = great_class_ideal_solutions_df.set_axis(['A+', 'A-'])\n",
    "great_class_ideal_solutions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ideal Solutions For \"Aproveitamento Mediano\" Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_class_ideal_solutions_df = pd.DataFrame(columns=weighted_classes_df.columns)\n",
    "medium_class_ideal_solutions_df.loc[0] = weighted_classes_df.loc['Aproveitamento Mediano']\n",
    "medium_class_ideal_solutions_df.loc[1] = weighted_classes_df.loc['Baixo Aproveitamento']\n",
    "medium_class_ideal_solutions_df = medium_class_ideal_solutions_df.set_axis(['A+', 'A-'])\n",
    "medium_class_ideal_solutions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ideal Solutions For \"Baixo Aproveitamento\" Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Easiness Score</th>\n",
       "      <th>Coherence Score</th>\n",
       "      <th>Quality Of Explanation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A+</th>\n",
       "      <td>[0.04761904761904763, 0.05, 0.20124223602484467]</td>\n",
       "      <td>[0.06666666666666668, 0.06666666666666667, 0.1...</td>\n",
       "      <td>[0.08571428571428572, 0.08333333333333333, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-</th>\n",
       "      <td>[0.19047619047619052, 0.25, 0.5031055900621116]</td>\n",
       "      <td>[0.2666666666666667, 0.3333333333333333, 0.279...</td>\n",
       "      <td>[0.34285714285714286, 0.41666666666666663, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Easiness Score  \\\n",
       "A+  [0.04761904761904763, 0.05, 0.20124223602484467]   \n",
       "A-   [0.19047619047619052, 0.25, 0.5031055900621116]   \n",
       "\n",
       "                                      Coherence Score  \\\n",
       "A+  [0.06666666666666668, 0.06666666666666667, 0.1...   \n",
       "A-  [0.2666666666666667, 0.3333333333333333, 0.279...   \n",
       "\n",
       "                         Quality Of Explanation Score  \n",
       "A+  [0.08571428571428572, 0.08333333333333333, 0.0...  \n",
       "A-  [0.34285714285714286, 0.41666666666666663, 0.2...  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_class_ideal_solutions_df = pd.DataFrame(columns=weighted_classes_df.columns)\n",
    "low_class_ideal_solutions_df.loc[0] = weighted_classes_df.loc['Baixo Aproveitamento']\n",
    "low_class_ideal_solutions_df.loc[1] = weighted_classes_df.loc['Otimo Aproveitamento']\n",
    "low_class_ideal_solutions_df = low_class_ideal_solutions_df.set_axis(['A+', 'A-'])\n",
    "low_class_ideal_solutions_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
